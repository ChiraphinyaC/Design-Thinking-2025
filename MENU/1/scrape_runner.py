#scrape_runner.py : ‡∏ï‡∏±‡∏ß ‚Äú‡∏£‡∏±‡∏ô‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏°‡∏≤‡∏Å‚Äù
#‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà ‡∏î‡∏∂‡∏á‡∏´‡∏•‡∏≤‡∏¢‡∏™‡∏π‡∏ï‡∏£‡∏à‡∏≤‡∏Å Kapook ‡∏ß‡∏ô‡∏•‡∏π‡∏õ‡∏´‡∏•‡∏≤‡∏¢ URL ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å CSV ‡∏™‡∏£‡πâ‡∏≤‡∏á dataset
import pandas as pd
from scraper import scrape_kapook
import time

# üî• ‡πÉ‡∏™‡πà‡∏•‡∏¥‡∏á‡∏Å‡πå‡∏™‡∏π‡∏ï‡∏£‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
URLS = [
    "https://cooking.kapook.com/view273026.html",
]


def main():
    all_rows = []

    for url in URLS:
        print("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏î‡∏∂‡∏á:", url)
        data = scrape_kapook(url)

        if not data:
            continue

        all_rows.append({
            "recipe_name": data["name"],
            "ingredients": "|".join(data["ingredients"]),
            "steps": "|".join(data["steps"]),
            "type": "",
            "difficulty": "",
            "time": "",
            "image": data["image"],
        })

        time.sleep(1)

    df = pd.DataFrame(all_rows)
    df.to_csv("recipes_dataset.csv", index=False, encoding="utf-8-sig")

    print("‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á recipes_dataset.csv ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")


if __name__ == "__main__":
    main()
