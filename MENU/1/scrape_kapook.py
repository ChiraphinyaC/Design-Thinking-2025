import requests
from bs4 import BeautifulSoup
import pandas as pd
import time
 
headers = {
    "User-Agent": "Mozilla/5.0"
}
 
# ----------------------------------
# ‡∏î‡∏∂‡∏á‡∏•‡∏¥‡∏á‡∏Å‡πå‡∏™‡∏π‡∏ï‡∏£‡∏à‡∏≤‡∏Å‡∏´‡∏ô‡πâ‡∏≤‡∏£‡∏ß‡∏°
# ----------------------------------
def get_recipe_links(list_url):
    response = requests.get(list_url, headers=headers)
    soup = BeautifulSoup(response.text, "html.parser")
 
    links = []
 
    for a in soup.find_all("a", href=True):
        href = a["href"]
        if "cooking.kapook.com/view" in href:
            if href.startswith("http"):
                links.append(href)
            else:
                links.append("https://cooking.kapook.com" + href)
 
    # ‡∏•‡∏ö‡∏•‡∏¥‡∏á‡∏Å‡πå‡∏ã‡πâ‡∏≥
    links = list(set(links))
 
    return links
 
 
# ----------------------------------
# ‡∏î‡∏∂‡∏á‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏™‡∏π‡∏ï‡∏£
# ----------------------------------
def scrape_kapook(url):
    response = requests.get(url, headers=headers)
    soup = BeautifulSoup(response.text, "html.parser")
 
    title_tag = soup.find("h1")
    recipe_name = title_tag.get_text(strip=True) if title_tag else "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏ä‡∏∑‡πà‡∏≠‡∏™‡∏π‡∏ï‡∏£"
 
    ingredients = []
    for li in soup.find_all("li"):
        text = li.get_text(strip=True)
        if any(unit in text for unit in ["‡∏Å‡∏£‡∏±‡∏°", "‡∏ä‡πâ‡∏≠‡∏ô", "‡∏ñ‡πâ‡∏ß‡∏¢", "‡∏ü‡∏≠‡∏á", "‡∏ä‡∏ï.", "‡∏ä‡∏ä.", "‡∏°‡∏•."]):
            ingredients.append(text)
 
    steps = []
    for p in soup.find_all("p"):
        text = p.get_text(strip=True)
        if text.startswith(("1.", "2.", "3.", "4.", "5.", "6.", "7.", "8.", "9.")):
            steps.append(text)
    steps = list(dict.fromkeys(steps))
    return {
        "recipe_name": recipe_name,
        "ingredients": ingredients,
        "steps": steps
    }
 
 
# ----------------------------------
# üî• ‡∏£‡∏±‡∏ô‡∏´‡∏•‡∏±‡∏Å
# ----------------------------------
if __name__ == "__main__":
 
    list_page = "https://cooking.kapook.com/"
 
    print("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏î‡∏∂‡∏á‡∏•‡∏¥‡∏á‡∏Å‡πå‡∏™‡∏π‡∏ï‡∏£...")
    recipe_links = get_recipe_links(list_page)
 
    print("‡∏û‡∏ö‡∏•‡∏¥‡∏á‡∏Å‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î:", len(recipe_links))
 
    all_data = []
 
    # ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Å‡πà‡∏≠‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ó‡∏î‡∏™‡∏≠‡∏ö (‡πÄ‡∏ä‡πà‡∏ô 10 ‡∏™‡∏π‡∏ï‡∏£‡πÅ‡∏£‡∏Å)
    for url in recipe_links[:10]:
        print("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏î‡∏∂‡∏á:", url)
 
        data = scrape_kapook(url)
 
        if data and len(data["ingredients"]) > 0:
            all_data.append({
                "recipe_name": data["recipe_name"],
                "ingredients_text": " | ".join(data["ingredients"]),
                "steps_text": " | ".join(data["steps"])
            })
 
        time.sleep(1)  # ‡∏´‡∏ô‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤ ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡πÇ‡∏î‡∏ô‡∏ö‡∏•‡πá‡∏≠‡∏Å
 
    df = pd.DataFrame(all_data)
    df.to_csv("recipes_dataset.csv", index=False, encoding="utf-8-sig")
 
    print("‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå recipes_dataset.csv ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
 